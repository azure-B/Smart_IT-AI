from config import config
from sentence_transformers import SentenceTransformer, util
from read_data import extract_speaker_text_from_json_in_folder
import torch
import os
import json
from openai import OpenAI
import sys
import io

# [í•„ìˆ˜] ì¶œë ¥(Print)ì€ UTF-8ë¡œ ê°•ì œ ê³ ì • (ì´ëª¨ì§€ ë° í•œê¸€ ì¶œë ¥ìš©)
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


# ==========================================
# [í•µì‹¬ ìˆ˜ì •] í•œê¸€ ì…ë ¥ ê¹¨ì§ ë°©ì§€ í•¨ìˆ˜
# ==========================================
def safe_input(prompt):
    """
    ìœˆë„ìš° ë„ì»¤ í™˜ê²½ì—ì„œ input() ì‚¬ìš© ì‹œ ë°œìƒí•˜ëŠ” UnicodeDecodeErrorë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    ë°ì´í„°ë¥¼ ë°”ì´íŠ¸(Raw Byte) ë‹¨ìœ„ë¡œ ë°›ì•„ì„œ UTF-8 ë˜ëŠ” CP949ë¡œ ë²ˆì—­ì„ ì‹œë„í•©ë‹ˆë‹¤.
    """
    print(prompt, end='', flush=True)
    try:
        # 1. í‘œì¤€ ì…ë ¥ ë²„í¼ì—ì„œ ë‚ ê²ƒì˜ ë°ì´í„° ì½ê¸°
        line = sys.stdin.buffer.readline()
        if not line: return ""  # EOF ì²˜ë¦¬

        # 2. UTF-8ë¡œ ë¨¼ì € ë””ì½”ë”© ì‹œë„ (ëŒ€ë¶€ë¶„ì˜ ë¦¬ëˆ…ìŠ¤/ë„ì»¤ í™˜ê²½)
        try:
            return line.decode('utf-8').strip()
        except UnicodeDecodeError:
            # 3. ì‹¤íŒ¨ ì‹œ ìœˆë„ìš° ê¸°ë³¸ ì¸ì½”ë”©(CP949)ìœ¼ë¡œ ë””ì½”ë”© ì‹œë„
            return line.decode('cp949').strip()
    except Exception:
        return ""


# ==========================================
# ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================

# 1. ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
LOCAL_MODEL_NAME = "exaone3.5"

# 2. Ollama ì£¼ì†Œ ì„¤ì •
default_url = "http://localhost:11434/v1"
OLLAMA_URL = os.getenv("OLLAMA_URL", default_url)

print(f"ğŸ”— AI ì—°ê²° ì£¼ì†Œ: {OLLAMA_URL}")

# Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    base_url=OLLAMA_URL,
    api_key="ollama"
)

# 3. ì¥ì¹˜ ìë™ ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"

print("-" * 30)
if device == "cuda":
    print(f"CUDA ì‚¬ìš© ì¤‘ ({torch.cuda.get_device_name(0)})")
else:
    print("CPU ì‚¬ìš© ì¤‘")
print("-" * 30)

EMBEDDING_FILE = config.EMBEDDING_FILE
TEXT_DATA_FILE = config.TEXT_DATA_FILE

# 4. ëª¨ë¸ ë¡œë“œ (SBERT)
model = SentenceTransformer('jhgan/ko-sbert-nli', device=device)

if os.path.exists(EMBEDDING_FILE) and os.path.exists(TEXT_DATA_FILE):
    print("--- ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤ ---")
    dataset_embeddings = torch.load(EMBEDDING_FILE, map_location=device)
    with open(TEXT_DATA_FILE, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
else:
    print("--- ë°ì´í„°ì…‹ ìƒì„± ë° ì„ë² ë”© ì‹œì‘ ---")
    # ê²½ë¡œê°€ ./Dataset ì¸ì§€ ../Dataset ì¸ì§€ í™˜ê²½ì— ë§ê²Œ í™•ì¸ í•„ìš” (í˜„ì¬ ./Datasetìœ¼ë¡œ ìˆ˜ì •ë¨)
    test_path = os.path.join("./Dataset", "Training")

    # í´ë”ê°€ ì—†ì„ ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬
    if not os.path.exists(test_path):
        # ë§Œì•½ ë„ì»¤ì—ì„œ ê²½ë¡œê°€ ë‹¤ë¥´ë‹¤ë©´ ../Datasetìœ¼ë¡œ ì‹œë„
        test_path = os.path.join("../Dataset", "Training")

    dataset = extract_speaker_text_from_json_in_folder(test_path)

    if not dataset:
        print(f"ì˜¤ë¥˜: ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {test_path}")
        exit()

    dataset_embeddings = model.encode(dataset, convert_to_tensor=True)

    torch.save(dataset_embeddings, EMBEDDING_FILE)
    with open(TEXT_DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)

print(f"--- ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ (ì´ {len(dataset)}ê°œ) ---")
print("-" * 30)

# ==========================================
# ë©”ì¸ ë£¨í”„
# ==========================================
while True:
    try:
        # [ìˆ˜ì •] input() ëŒ€ì‹  safe_input() ì‚¬ìš©
        user_speech = safe_input(" ğŸ’¬ ì…ë ¥ (ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'): ")
    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    if user_speech:  # ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        if "ì¢…ë£Œ" in user_speech.replace(" ", ""):
            print(" í”„ë¡œê·¸ë¨ ì¢…ë£Œ ")
            break

        # 1. [ê²€ìƒ‰] (Retrieval)
        user_speech_embedding = model.encode(user_speech, convert_to_tensor=True)
        hits = util.semantic_search(user_speech_embedding, dataset_embeddings, top_k=1)

        top_hit = hits[0][0]
        matched_text = dataset[top_hit['corpus_id']]
        similarity_score = top_hit['score']

        if "ë‹µë³€:" in matched_text:
            reference_answer = matched_text.split("ë‹µë³€:", 1)[1].strip()
        else:
            reference_answer = matched_text

        print(f"\n[ì°¸ê³  ìë£Œ ê²€ìƒ‰ ì™„ë£Œ] (ìœ ì‚¬ë„: {similarity_score:.4f})")

        # 2. [ìƒì„±] (Generation)
        print(f"{LOCAL_MODEL_NAME} ìˆ˜ì˜ì‚¬ê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")

        try:
            completion = client.chat.completions.create(
                model=LOCAL_MODEL_NAME,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ìˆ˜ì˜ì‚¬ì…ë‹ˆë‹¤. "
                            "ì œê³µëœ [ì°¸ê³  ì •ë³´] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. "
                            "ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ê³ , 3~4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ë”°ëœ»í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”."
                            "ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”."
                        )
                    },
                    {
                        "role": "user",
                        "content": f"ì‚¬ìš©ì ì§ˆë¬¸: {user_speech}\n\n[ì°¸ê³  ì •ë³´]: {reference_answer}"
                    }
                ],
                temperature=0.7
            )
            final_answer = completion.choices[0].message.content

            print("\n[ìˆ˜ì˜ì‚¬ ë‹µë³€]:")
            print(final_answer)

        except Exception as e:
            print(f"\n Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
            print("\n[ì›ë³¸ ë‹µë³€ (Fallback)]:")
            print(reference_answer)

    else:
        # ì—”í„°ë§Œ ì³¤ì„ ë•Œ
        pass

    print("=" * 30)