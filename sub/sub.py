from config import config
from sentence_transformers import SentenceTransformer, util
from read_data import extract_speaker_text_from_json_in_folder
import torch
import os
import json
from openai import OpenAI  # [ì¶”ê°€] Ollama ì—°ê²°ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬

# 1. ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (í„°ë¯¸ë„ì—ì„œ 'ollama pull exaone3.5' ë¯¸ë¦¬ ì‹¤í–‰ í•„ìš”)
LOCAL_MODEL_NAME = "exaone3.5"

# 2. Ollama ì£¼ì†Œ ì„¤ì •
default_url = "http://localhost:11434/v1"
OLLAMA_URL = os.getenv("OLLAMA_URL", default_url)

print(f"ğŸ”— AI ì—°ê²° ì£¼ì†Œ: {OLLAMA_URL}")

# Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    base_url=OLLAMA_URL,
    api_key="ollama"  # OllamaëŠ” í‚¤ê°€ í•„ìš” ì—†ì§€ë§Œ í˜•ì‹ìƒ ì…ë ¥
)

# ==========================================
# 1. ì¥ì¹˜ ìë™ ì„¤ì •
# ==========================================
device = "cuda" if torch.cuda.is_available() else "cpu"

print("-" * 30)
if device == "cuda":
    print(f"CUDA ì‚¬ìš© ì¤‘ ({torch.cuda.get_device_name(0)})")
else:
    print("CPU ì‚¬ìš© ì¤‘")
print("-" * 30)

EMBEDDING_FILE = config.EMBEDDING_FILE
TEXT_DATA_FILE = config.TEXT_DATA_FILE

# 2. ëª¨ë¸ ë¡œë“œ (SBERT: ê²€ìƒ‰ ë‹´ë‹¹)
model = SentenceTransformer('jhgan/ko-sbert-nli', device=device)

if os.path.exists(EMBEDDING_FILE) and os.path.exists(TEXT_DATA_FILE):
    print("--- ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤ ---")
    dataset_embeddings = torch.load(EMBEDDING_FILE, map_location=device)
    with open(TEXT_DATA_FILE, 'r', encoding='utf-8') as f:
        dataset = json.load(f)

else:
    print("--- ë°ì´í„°ì…‹ ìƒì„± ë° ì„ë² ë”© ì‹œì‘ ---")
    test_path = os.path.join("../Dataset", "Training")
    dataset = extract_speaker_text_from_json_in_folder(test_path)

    if not dataset:
        print("ì˜¤ë¥˜: ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()
    dataset_embeddings = model.encode(dataset, convert_to_tensor=True)

    torch.save(dataset_embeddings, EMBEDDING_FILE)
    with open(TEXT_DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)

print(f"--- ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ (ì´ {len(dataset)}ê°œ) ---")
print("-" * 30)

while True:
    try:
        user_speech = input(" ğŸ’¬ ì…ë ¥ (ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'): ")
    except EOFError:
        break

    if user_speech.strip():
        if "ì¢…ë£Œ" in user_speech.replace(" ", ""):
            print(" í”„ë¡œê·¸ë¨ ì¢…ë£Œ ")
            break

        # 1. [ê²€ìƒ‰] ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€ ì°¾ê¸° (Retrieval)
        user_speech_embedding = model.encode(user_speech, convert_to_tensor=True)
        hits = util.semantic_search(user_speech_embedding, dataset_embeddings, top_k=1)

        # ê°€ì¥ ìœ ì‚¬í•œ 1ê°œë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        top_hit = hits[0][0]
        matched_text = dataset[top_hit['corpus_id']]
        similarity_score = top_hit['score']

        # ë‹µë³€ ë¶€ë¶„ë§Œ ì¶”ì¶œ (Contextë¡œ ì‚¬ìš©)
        if "ë‹µë³€:" in matched_text:
            reference_answer = matched_text.split("ë‹µë³€:", 1)[1].strip()
        else:
            reference_answer = matched_text

        print(f"\[ì°¸ê³  ìë£Œ ê²€ìƒ‰ ì™„ë£Œ] (ìœ ì‚¬ë„: {similarity_score:.4f})")
        # ë””ë²„ê¹…ìš©ìœ¼ë¡œ ì›ë³¸ì´ ë³´ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
        # print(f"ì°¸ê³  ë‚´ìš©: {reference_answer[:100]}...")

        # 2. [ìƒì„±] Ollamaì—ê²Œ ìš”ì•½ ë° ë‹µë³€ ìƒì„± ìš”ì²­ (Generation)
        print(f"{LOCAL_MODEL_NAME} ìˆ˜ì˜ì‚¬ê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")

        try:
            completion = client.chat.completions.create(
                model=LOCAL_MODEL_NAME,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ìˆ˜ì˜ì‚¬ì…ë‹ˆë‹¤. "
                            "ì œê³µëœ [ì°¸ê³  ì •ë³´] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. "
                            "ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ê³ , 3~4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ë”°ëœ»í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”."
                            "ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”."
                        )
                    },
                    {
                        "role": "user",
                        "content": f"ì‚¬ìš©ì ì§ˆë¬¸: {user_speech}\n\n[ì°¸ê³  ì •ë³´]: {reference_answer}"
                    }
                ],
                temperature=0.7  # ì°½ì˜ì„± ì¡°ì ˆ
            )
            final_answer = completion.choices[0].message.content

            print("\n[ìˆ˜ì˜ì‚¬ ë‹µë³€]:")
            print(final_answer)

        except Exception as e:
            print(f"\n Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
            print("\n[ì›ë³¸ ë‹µë³€]:")
            print(reference_answer)

    else:
        print("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    print("=" * 30)